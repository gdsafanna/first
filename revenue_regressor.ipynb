{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "#import plt_cr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from IPython.html.widgets import *\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "TIME_FORMAT = \"%Y-%m-%d\"\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roll(y, min_y, max_y):\n",
    "    return (y - min_y) / (max_y - min_y)\n",
    "def unroll(y, min_y, max_y):\n",
    "    return (max_y - min_y) * y + min_y\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test sets, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##train test sets to use\n",
    "train = pd.read_csv('../train_test_sets/4_cat_features/regressor-train.csv')\n",
    "test = pd.read_csv('../train_test_sets/4_cat_features/regressor-test-both.csv')\n",
    "\n",
    "## loading model you are going to use \n",
    "model=joblib.load('xgb_regressor_wd_we_bf.pkl')\n",
    "\n",
    "##columns to drop from the datasets\n",
    "cols_to_drop=['order_date','prod_id', 'sku_id', '_merge', 'rv']\n",
    "\n",
    "train = shuffle(train)\n",
    "test = shuffle(test)\n",
    "\n",
    "train = train.sort_values(by=['order_date'])\n",
    "test = test.sort_values(by=['order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train[\"rv\"]\n",
    "Y_Val = test[\"rv\"]\n",
    "\n",
    "min_y = min(Y.min(), Y_Val.min())\n",
    "max_y = max(Y.max(), Y_Val.max())\n",
    "\n",
    "Y = roll(Y, min_y=min_y, max_y=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(prod_id=323407, sku_id=34006140):\n",
    "    subtest=test[(test.prod_id==prod_id)&(test.sku_id==sku_id)]\n",
    "    X_Val = subtest.drop(cols_to_drop, axis=1)\n",
    "    Y_Val = subtest[\"rv\"]\n",
    "    Z_Val = subtest[[\"prod_id\",\"sku_id\",\"order_date\",\"rv\"]]\n",
    "    \n",
    "    Y_Val = roll(Y_Val, min_y=min_y, max_y=max_y)\n",
    "    Z_Val['Y']=Y_Val\n",
    "    \n",
    "    p = model.predict(X_Val)\n",
    "    Z_Val[\"p\"]=p\n",
    "    Z_Val[\"predicted revenue\"]=unroll(p, min_y=min_y, max_y=max_y)\n",
    "    \n",
    "    print (\"Test predict r2-score: {}\".format(r2_score(Y_Val, p)))\n",
    "    print (\"Test predict explained_variance_score: {}\".format(explained_variance_score(Y_Val, p)))\n",
    "    print (\"Test predict mean_absolute_error: {}\".format(mean_absolute_error(Y_Val, p)))\n",
    "    print (\"Test predict mean_squared_error: {}\".format(mean_squared_error(Y_Val, p)))\n",
    "    #print (\"Test predict mean_squared_log_error: {}\".format(mean_squared_log_error(Y_Val, p)))\n",
    "    print (\"Test predict median_absolute_error: {}\".format(median_absolute_error(Y_Val, p)))\n",
    "    \n",
    "    print (\"Test predict unscaled revenue mean_squared_error: {}\".format(mean_squared_error(Z_Val['rv'], Z_Val[\"predicted revenue\"])))\n",
    "    print (\"Test predict unscaled revenue median_absolute_error: {}\".format(median_absolute_error(Z_Val['rv'], Z_Val[\"predicted revenue\"])))\n",
    "    s=train[[\"prod_id\",\"sku_id\",\"order_date\",\"rv\"]][(train.prod_id==prod_id)&(train.sku_id==sku_id)].sort_values(by=['order_date'])\n",
    "    s['Y']=Y\n",
    "    s=s.append(Z_Val)\n",
    "    s=s.groupby(['prod_id','sku_id','order_date']).sum()\n",
    "    s.reset_index(inplace=True)\n",
    "    s['order_date']=s['order_date'].apply(lambda x: datetime.strftime(datetime(1970,1,1)+timedelta(days=x),TIME_FORMAT))\n",
    "    s.set_index('order_date',inplace=True)\n",
    "    s.columns=[\"prod_id\",\"sku_id\",\"Y\",\"p\",\"predicted revenue\",\"actual revenue\"]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dct={}\n",
    "with open ('../train_test_sets/subset.csv') as test_full:\n",
    "    for line in test_full:\n",
    "        line=line.split(',')\n",
    "        if line[0]!='prod_id':\n",
    "            l0=int(line[0])\n",
    "            l1=int(line[1])\n",
    "            if l0 in test_dct.keys():\n",
    "                if l1 not in test_dct[l0]:\n",
    "                    test_dct[l0].append(l1)\n",
    "            else:\n",
    "                test_dct[l0]=[l1]\n",
    "\n",
    "p_id=list(test_dct.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4aac9c1499428c85a8526a6160a860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.sku_change>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_widget = widgets.Dropdown(options=p_id, value=p_id[0],description='Product', disabled=False)\n",
    "y_widget = widgets.Dropdown(options=test_dct[p_id[0]], value=test_dct[p_id[0]][0],description='SKU', disabled=False)\n",
    "\n",
    "def update_y(*args):\n",
    "    y_widget.options = test_dct[x_widget.value]\n",
    "x_widget.observe(update_y, 'value')\n",
    "\n",
    "def sku_change(product,sku):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    csfont = {'fontname':'Comic Sans MS','fontsize':25}\n",
    "    dframe=test_prediction(prod_id=product, sku_id=sku)[['actual revenue','predicted revenue']]\n",
    "    dframe=dframe.plot(figsize=(25, 8),style=['ro-','bo-'])\n",
    "    plt.legend(loc='upper left',fontsize=20)\n",
    "    plt.title(\"Revenue of SKU \"+str(sku),**csfont)\n",
    "    plt.xticks(rotation=17,fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.show()\n",
    "prod_id_lst=[]\n",
    "interact(sku_change, product=x_widget, sku=y_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models (0.7 of training set have been used for training, 0.1 of test set for validation)\n",
    "\n",
    "#################################################\n",
    "#### 1. Model with weekday (indicator shows weekday)\n",
    "##### Test predict r2-score: 0.5299134246068948\n",
    "##### Test predict explained_variance_score: 0.531469182765118\n",
    "##### Test predict mean_absolute_error: 5.6560362707825045e-05\n",
    "##### Test predict mean_squared_error: 1.260108074665276e-07\n",
    "##### Test predict median_absolute_error: 1.681574030953925e-05\n",
    "\n",
    "#################################################\n",
    "#### 2. Model with weekday feature, order_date has been excluded\n",
    "##### Test predict r2-score: 0.5742968039683343\n",
    "##### Test predict explained_variance_score: 0.5744179952970745\n",
    "##### Test predict mean_absolute_error: 6.162475825623931e-05\n",
    "##### Test predict mean_squared_error: 1.1434343587423002e-07\n",
    "##### Test predict median_absolute_error: 2.4781280444585718e-05\n",
    "\n",
    "#################################################\n",
    "#### 3. Model with weekday (wd), weekend indicator (we) and \"high sales season 24-26 nov\" (bf)\n",
    "##### Test predict r2-score: 0.5896162971036237\n",
    "##### Test predict explained_variance_score: 0.5898569718185549\n",
    "##### Test predict mean_absolute_error: 6.183339355173199e-05\n",
    "##### Test predict mean_squared_error: 1.0911726138334042e-07\n",
    "##### Test predict median_absolute_error: 2.452127773722168e-05\n",
    "\n",
    "#################################################\n",
    "#### 4. Model with weekday (wd), weekend indicator (we) and \"high sales season 24-26 nov\" (bf) and categorical features of SKU\n",
    "##### Test predict r2-score: 0.535666973876717\n",
    "##### Test predict explained_variance_score: 0.5370250930124898\n",
    "##### Test predict mean_absolute_error: 5.665384438628712e-05\n",
    "##### Test predict mean_squared_error: 1.2308352349169409e-07\n",
    "##### Test predict median_absolute_error: 1.7476406355854124e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
